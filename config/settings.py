LLM_PROVIDER = "GROQ"
LLM_MODEL_NAME = "llama-3.3-70b-versatile"
#llama-3.3-70b-versatile
#llama-3.1-8b-instant
LLM_TEMPERATURE = 0.7

EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

TOP_K = 3
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

PINECONE_INDEX_NAME = "hybrid-search-langchain-pinecone"

MAX_HISTORY_MESSAGES = 14